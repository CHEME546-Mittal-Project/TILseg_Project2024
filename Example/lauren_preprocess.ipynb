{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Kmeans-Dbscan Segmentation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **How to Run Notebook**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up `virtual conda environment` if you have not already done so. Uncomment to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda create conda create ../environments/environment.yml --no-builds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code editor running this Jupyter Notebook, change the kernel to the new `TILSEG_PROJECT2024` conda environment. THis will allow you to use the needed imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Update the `respository_path` variable to use the 'TILSEG_PROJECT2024' Cloned Github Folder path. \n",
    "This path is needed to access the example files used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_path = os.getcwd()\n",
    "repository_path = os.path.dirname(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run the `Initalization Block`. This is necessary as Python adds a directory for this notebook to the list of locations where modules can be searched from when importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(repository_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Import the needed modules in the `Import Block`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External library imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "#Local Library Imports\n",
    "from tilseg.preprocessing import preprocess\n",
    "from tilseg.seg import segment_TILs\n",
    "from tilseg.model_selection import opt_kmeans\n",
    "from tilseg.refine_kmeans import KMeans_superpatch_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Data download block. Used to install the `gdown` module to access data from google drive. Uncoment to run, but you only need to run this once per laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting beautifulsoup4 (from gdown)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from gdown)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests[socks] in /Users/laurenfrank/miniconda3/envs/546proj_mac/lib/python3.11/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/laurenfrank/miniconda3/envs/546proj_mac/lib/python3.11/site-packages (from gdown) (4.65.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/laurenfrank/miniconda3/envs/546proj_mac/lib/python3.11/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/laurenfrank/miniconda3/envs/546proj_mac/lib/python3.11/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/laurenfrank/miniconda3/envs/546proj_mac/lib/python3.11/site-packages (from requests[socks]->gdown) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/laurenfrank/miniconda3/envs/546proj_mac/lib/python3.11/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/laurenfrank/miniconda3/envs/546proj_mac/lib/python3.11/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, filelock, beautifulsoup4, gdown\n",
      "Successfully installed beautifulsoup4-4.12.3 filelock-3.13.1 gdown-5.1.0 soupsieve-2.5\n"
     ]
    }
   ],
   "source": [
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Current repository contains the following file strucutre of the `Example` Folder:**\n",
    "#### These files will be used to walk through an example of using TILSEG_PROJECT2024 in analysis.<br>\n",
    "<img src= \"Notebook_Images/Image_9.png\" style=\"width: 600px;\"><br>\n",
    "#### Dont worry - these folders should be empty. They will be filled via the exercises in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Core Features Overview**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The TILSEG_PROJECT2024 software package is intended for use in breast cancer slide segmentation analysis, aimed at accelerating breast cancer detection. This package consists for 4 main components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From 2023 Capstone (OLD COMPONENTS):\n",
    "### 1. <u>Preprocessing (preprocessing.py):</u>\n",
    "<img src= \"Notebook_Images/image_7.png\" style=\"width: 600px;\">\n",
    "<img src= \"Notebook_Images/image_8.png\" style=\"width: 597px;\">\n",
    "\n",
    "#### creates superpatch .tif file from cropped 3000 by 4000 pixel patches from a stained breast cancer slide. The original image is segmented into all possible patches where a select number (default: 6) are chosen that represent different sections of grays scales from a guassian distribution. \n",
    "\n",
    "#### Sub-Components:\n",
    "* #### test\n",
    "<br>\n",
    "<span style=\"background-color: rgba(255, 255, 0, 0.5); font-size: 20px;\">UPDATES/BUG FIXES FROM 2024 PROJECT: </span>\n",
    "\n",
    "* #### Changed the os handling to read in the full filepaths of each .svs image since the original code was using only the filename (this led to filepath exception errors)\n",
    "* #### def get_superpatch_patches (def preprocess << def get_superpatch_patches) updated to now have a random state argument to allow for the superpatch to be made from the same patches each time a notebook is run\n",
    "* #### def sort_patches (def preprocess << def main_preprocessing << def sort_patches) was updated to use a Gaussian Mixture distribution to identify the peaks associated with the pink tissue and white background to reduce the background in the returned superpatches. Original method was documented very poorly and did not accurately remove white background patches, as shown below.\n",
    "\n",
    "    | Superpatch - Old Sort Patches Function   | Superpatch - New Sort Patches Function  |\n",
    "    |--------------|--------------|\n",
    "    | <img src= \"Notebook_Images/super_before.png\" style=\"width: 570px;\"> | <img src= \"Notebook_Images/image_8.png\" style=\"width: 570px;\">|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. <u>Image Segmentation (seg.py >> def segment_TILs) </u>\n",
    "#### Applies a clustering model (e.g. KMeans) on a superpath and applies the model to a folder of patches to generate the following files: TILs overlayed on the original H&E patch, binary segmentation masks of each cluster, individual clusters overlayed on the original patch, image of all the clusters, and a CSV file containing countour information of each TIL segmented from the patch. Currently accepts fitted and non-fitted 'KMeans', 'DBSCAN', 'OPTICS', 'BIRCH' algorithms.\n",
    "\n",
    "#### Sub-Components:\n",
    "* #### def image_postprocessing\n",
    "<br>\n",
    "<span style=\"background-color: rgba(255, 255, 0, 0.5); font-size: 20px;\">UPDATES/BUG FIXES FROM 2024 PROJECT: </span>\n",
    "\n",
    "* #### def segment_TILS was updated to take in a `multiple_images` flag to be able to be able to fit a kmeans model to a patch rather than just a superpatch to use the predicted clusters on this patch in downstream scoring\n",
    "\n",
    "* #### def immune_cluster_analyzer (def segment_TILS << def image_postprocessing << def immune_cluster_analyzer) was updated to return the `cluster mask` of the highest TIL contour count to be able to do further segmenetation using dbscan (explained in next section)\n",
    "\n",
    "* #### def draw_til_images (def segment_TILS << def image_postprocessing << def draw_til_images) had a bug for a wrong array type fed to .drawContours package that was fixed\n",
    "\n",
    "* #### def segment_TILS had a bug fixed to only check for .tif images in a patches folder (avoid errors of hidden .ipynb or files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From 2024 Software Project (NEW COMPONENTS):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. <u>Spatial Modeling (refine_kmeans.py >> def kmean_to_spatial_model wrappers) </u>\n",
    "#### Created wrappers to run def segment_TILS on a folder of patches and use the output kmeans labels of the highest contour cluster to do further clustering with dbscan. Similarily, a wrapper was created to run segment_TILS on a single patch as both the superpath and patch to run dbscan on-itself and generate a ground truth scoring dbscan classification on the cluster.\n",
    "\n",
    "#### Sub-Components:\n",
    "* #### mask_to_features\n",
    "* #### km_dbscan_wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <u>Scoring / Preprocessing Updates (functions HERE) </u>\n",
    "#### Hanson and Stanley add information about what you did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <u>Bug Fixes from Original Code</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Example Walkthrough**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Pre-Preprocessing Step on a Slide Image\n",
    "### This section will show you how to utilize the preprocessing functions to construct a superpatch and a folder of associated slide patches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. To begin, download a sample Raw Slide Image (.Svs) by running the block below. This file is stored in a public Google Drive, as the filesize is too large to upload to Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1_aR-Vwd0B3suQW214zfkLudl6HK3w4q3\n",
      "From (redirected): https://drive.usercontent.google.com/download?id=1_aR-Vwd0B3suQW214zfkLudl6HK3w4q3&confirm=t&uuid=6bb0bda8-cbd0-4d6f-b609-2fea9a607881\n",
      "To: /Users/laurenfrank/TilsegV2/Example/Image_Files/TCGA-A2-A0CW-01Z-00-DX1.svs\n",
      "100%|████████████████████████████████████████| 667M/667M [00:24<00:00, 27.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 'https://drive.google.com/uc?id=1_aR-Vwd0B3suQW214zfkLudl6HK3w4q3' -O \"Image_Files/TCGA-A2-A0CW-01Z-00-DX1.svs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Slide Image (.svs) should have been saved to the `Image_Files` Folder. This file will be used in the next step.\n",
    "<img src= \"Notebook_Images/Image_4.png\" style=\"width: 165px;\">, <span style=\"font-size: 6em;\">&rarr;</span> <img src= \"Notebook_Images/image_5.png\" style=\"width: 170px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create the Superpatch and Patch Images Using the `Preprocess` Function in `Tilseg.Processing` Module\n",
    "- #### Using the .svs image, the preprocess function will create a superpatch using 6 of the total patches. Feel free to experiment with a different patch sizes (e.g. 3, 9, 12, ...) to see how this affects the superpatch.\n",
    "- #### Random state of 13 was specified to make notebook consistent between runs\n",
    "- #### The filepath of the .svs image will be printed along with the amount of pixels lost during the patch making phase\n",
    "- #### NOTE: `preprocess` can be used on a folder of .svs images rather than just the one slide image (as was done in this example), but this will significantly increase the run time. When using multiple images, still only one superpatch would be made, but it would be made of (num_patches * num_csv_images) patches (e.g. 6 patches * 2 .csv images = 12 patches in superpatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/laurenfrank/TilsegV2/Example/Image_Files/TCGA-A2-A0CW-01Z-00-DX1.svs\n",
      "Percent of pixels lost in pre-processing for TCGA-A2-A0CW-01Z-00-DX1.svs:                       1.7593642775049286e-06 %\n"
     ]
    }
   ],
   "source": [
    "path = repository_path + '/Example/Image_Files'\n",
    "superpatch = preprocess(path, patches=6, training=True, save_im=True,random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Before     | After    |\n",
    "|--------------|--------------|\n",
    "| <img src= \"Notebook_Images/Image_4.png\" style=\"width: 165px;\">, <span style=\"font-size: 6em;\">&rarr;</span> <img src= \"Notebook_Images/image_5.png\" style=\"width: 170px;\"> | <img src= \"Notebook_Images/Image_4.png\" style=\"width: 170px;\">, <span style=\"font-size: 6em;\">&rarr;</span> <img src= \"Notebook_Images/image_6.png\" style=\"width: 500px;\"> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Creates Three_Patches_Example Folder & Single_Patch_Example Folders and Move Patches to these Folders\n",
    "\n",
    "#### - For sake of time, only three images from the created folder \"TCGA-A2-...\" will be used in model construction. The 3 patches chosen had a good ratio of pink (breast tissue) to slide background (white), which will be useful in downstream analysis:\n",
    "* #### position_7_8tissue.tif\n",
    "* #### position_14_20tissue.tif\n",
    "* #### position_6_16tissue.tif\n",
    "\n",
    "#### - Run the below block to construct these two folders in addition to Sub Result Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!mkdir Image_Files/Three_Patches_Example\n",
    "!mv Image_Files/TCGA-A2-A0CW-01Z-00-DX1/position_7_8tissue.tif Image_Files/TCGA-A2-A0CW-01Z-00-DX1/position_14_20tissue.tif Image_Files/TCGA-A2-A0CW-01Z-00-DX1/position_6_16tissue.tif Image_Files/Three_Patches_Example\n",
    "\n",
    "!mkdir Image_Files/Single_Patch_Example\n",
    "!cp Image_Files/Three_Patches_Example/position_7_8tissue.tif Image_Files/Single_Patch_Example/position_7_8tissue.tif\n",
    "\n",
    "!mkdir Results/Image_Seg_Case_i\n",
    "!mkdir Results/Image_Seg_Case_ii\n",
    "!mkdir Results/Dbscan_Case_i\n",
    "!mkdir Results/Dbscan_Case_ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `Image_Files` Folder you should see:\n",
    "\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_10.png\" width=\"180\">  \n",
    "<span style=\"font-size: 6em;\">&rarr;</span>\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_11.png\" width=\"440\"><br>\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_13.png\" width=\"180\">\n",
    "<span style=\"font-size: 6em;\">&rarr;</span>\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_14.png\" width=\"180\"><br>\n",
    "\n",
    "Inside the `Results` Folder you should see:<br>\n",
    "\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_21.png\" width=\"175\">\n",
    "<span style=\"font-size: 6em;\">&rarr;</span>\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_20.png\" width=\"610\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Image Sementation\n",
    "### This section will walk through how to use the segmentation functions to train a kmeans model on a superpatch or test the ground-truth prediction of a single patch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case i: Running Segment_TILS on a Single Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. In Section A, a single patch was saved to the `Single_Patch_Example` Folder. This will file will be used in the demonstration of the Single Patch Functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `position_7_8tissues.tif`<br>\n",
    "<img src= \"Notebook_Images/image_12.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Open the Patch Image and Normalize the Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_path = repository_path + '/Example/Image_Files/Single_Patch_Example/position_7_8tissue.tif'\n",
    "img = Image.open(patch_path)\n",
    "numpy_img = np.array(img)\n",
    "numpy_img_reshape = np.float32(numpy_img.reshape((-1, 3))/255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Optimize the Kmeans Model on Patch (Almost always 4 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_dict = opt_kmeans(numpy_img_reshape,n_clusters = [2,3,4,6,7,8,9,10])\n",
    "kmeans_fit = KMeans_superpatch_fit(patch_path,hyperparameter_dict, random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Run segment_TILS\n",
    "* ##### Since we will be running the segmentation on a single patch, we will set the multiple_images flag = False. This also means that the in_dir_path should only be the path to the patch rather than to a folder of patches, as we will show in the next case.\n",
    "* ##### It should be noted that segment_TILS can also create/fit a model when passed in a hyperparameter dict and algorithm type; however, since the `KMeans_superpatch_fit` already returns a fitted model, this feature was bypassed via the `model` argument. If you chose to use it, you would put None into the `model` argument and feed the parameters into the `hyperparameter_dict` argument.\n",
    "* ##### Lastly, this notebook was inteded to showcase the implementation of KMeans-Dbscan, so only KMeans was used. However, this function can be fed KMeans, DBSCAN, BIRCH, or OPTICS models - not just KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIL_count_dict, kmean_labels_dict, cluster_mask_dict, cluster_index = segment_TILs(in_dir_path = patch_path,\n",
    "                                                        out_dir_path = repository_path + '/Example/Results/Image_Seg_Case_i',\n",
    "                                                        hyperparameter_dict = None,\n",
    "                                                        algorithm = 'KMeans',\n",
    "                                                        model = kmeans_fit,\n",
    "                                                        save_TILs_overlay = True,\n",
    "                                                        save_cluster_masks = True,\n",
    "                                                        save_cluster_overlays = True,\n",
    "                                                        save_all_clusters_img = True,\n",
    "                                                        save_csv = True,\n",
    "                                                        multiple_images = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above block, a kmeans model was fitted and predicted on the single patch. This type of function can be used to validate the results from a superpatch fitted model onto this patch - this will be done in case ii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Exploring the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1\n",
      "Filepath: position_7_8tissue\n",
      "Cluster Labels: [0 0 0 0 2 2 2 2 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 3 3 3 3]\n",
      "Unique Labels: {0, 1, 2, 3}\n",
      "Cluster label number that had the most contours: 1\n",
      "TIL_count of cluster 1: 2742\n"
     ]
    }
   ],
   "source": [
    "for i,key in enumerate(kmean_labels_dict):\n",
    "    print(f'File {i+1}')\n",
    "    print(f'Filepath: {key}') \n",
    "    print(f'Cluster Labels: {kmean_labels_dict[key][:30]}')\n",
    "    print(f'Unique Labels: {set(kmean_labels_dict[key])}')\n",
    "    print(f'Cluster label number that had the most contours: {cluster_index}')\n",
    "    print(f'TIL_count of cluster {cluster_index}: {TIL_count_dict[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see above, this image was found to have 4 optimzed clusters (0,1,2,3) and cluster 3 has the most TIL contours of 2742! Moreover, the clustering and contour map plots can be found in the `Clustering` Folder in `Results/Image_Seg_Case_i`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/Image_1.png\" width=\"200\">  \n",
    "<span style=\"font-size: 6em;\">&rarr;</span>\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_2.png\" width=\"200\">\n",
    "<span style=\"font-size: 6em;\">&rarr;</span>\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_16.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When zoomed in on the `AllClusters.jpg`, `ContourMask.jpg`, and `ContourOverlap.jpg`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_17.png\" width=\"400\">\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_18.png\" width=\"400\">  \n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_19.png\" width=\"400\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The KMeans clsters can be shown in the first image, while the binary mask/contour map of cluster 3 can be seen in the second image (cluster with the most small, round contours). This cluster was then overlaid the original raw image in the third figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case ii: Running Segment_TILS on a Folder of Patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Like in Case i, the images placed into the `Three_Patches_Example` Folder will now be used for analysis Multiple Image Functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `position_7_8tissues.tif`, `position_7_8tissues.tif`, `position_7_8tissues.tif` <br>\n",
    "<img src= \"Notebook_Images/image_15.png\" style=\"width: 700px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Open the Superpatch Image and Normalize the Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "superpatch_path = repository_path + '/Example/Image_Files/superpatch_training.tif'\n",
    "img = Image.open(superpatch_path)\n",
    "numpy_img = np.array(img)\n",
    "numpy_img_reshape = np.float32(numpy_img.reshape((-1, 3))/255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Optimize the Kmeans Model on Patch (Almost always 4 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_dict = opt_kmeans(numpy_img_reshape,n_clusters = [2,3,4,6,7,8,9,10])\n",
    "kmeans_fit = KMeans_superpatch_fit(superpatch_path,hyperparameter_dict,random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Run segment_TILS\n",
    "* ##### Since we will be running the segmentation on a folder of patches, we will set the multiple_images flag = True. This also means that the in_dir_path should be the path to the direcctory of patches (unlike before where it was the path to the single image)\n",
    "* #### In case ii, the superpatch is used to fit a KMeans model that is then fed into the segment_TILS function and predicted ontop of the separate patches in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIL_count_dict, kmean_labels_dict, cluster_mask_dict, cluster_index = segment_TILs(in_dir_path = patch_path,\n",
    "                                                        out_dir_path = repository_path + '/Example/Results/Image_Seg_Case_ii',\n",
    "                                                        hyperparameter_dict = None,\n",
    "                                                        algorithm = 'KMeans',\n",
    "                                                        model = kmeans_fit,\n",
    "                                                        save_TILs_overlay = True,\n",
    "                                                        save_cluster_masks = True,\n",
    "                                                        save_cluster_overlays = True,\n",
    "                                                        save_all_clusters_img = True,\n",
    "                                                        save_csv = True,\n",
    "                                                        multiple_images = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above block, a kmeans model was fitted and predicted on the single patch. This type of function can be used to validate the results from a superpatch fitted model onto this patch - this will be done in case ii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Kmeans-Dbscan Model on Same Patch - Kmeans fed into Dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From 2024 Software Project (NEW COMPONENTS):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Multiple Images (Predicting Superpatch Model on Superpatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Segment_TILS on Folder of Patches from Slide - KMeans Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Kmeans-Dbscan Model on Superpatch and Folder of Patches - KMeans fed into Dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found hyperparameters. Time took: 4.0150078694025675 minutes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtilseg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kmean_to_spatial_model_superpatch_wrapper\n\u001b[0;32m----> 2\u001b[0m im_labels, dbscan_model, cluster_mask_dict \u001b[38;5;241m=\u001b[39m \u001b[43mkmean_to_spatial_model_superpatch_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuperpatch_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrepository_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Example/Image Files/superpatch_training.tif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43min_dir_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrepository_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExample/Image Files/TCGA-A2-A0CW-01Z-00-DX1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mspatial_hyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_samples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mout_dir_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrepository_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExample/Results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msave_TILs_overlay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msave_cluster_masks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msave_cluster_overlays\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msave_all_clusters_img\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msave_csv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TILseg_Project2024/tilseg/seg.py:853\u001b[0m, in \u001b[0;36mkmean_to_spatial_model_superpatch_wrapper\u001b[0;34m(superpatch_path, in_dir_path, spatial_hyperparameters, n_clusters, out_dir_path, save_TILs_overlay, save_cluster_masks, save_cluster_overlays, save_all_clusters_img, save_csv)\u001b[0m\n\u001b[1;32m    851\u001b[0m tf \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound hyperparameters. Time took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(tf\u001b[38;5;241m-\u001b[39mt0)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 853\u001b[0m kmeans_fit \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans_superpatch_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuperpatch_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhyperparameter_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m tf2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted Kmeans fitting. Time took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(tf2\u001b[38;5;241m-\u001b[39mtf)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/TILseg_Project2024/tilseg/refine_kmeans.py:97\u001b[0m, in \u001b[0;36mKMeans_superpatch_fit\u001b[0;34m(patch_path, hyperparameter_dict)\u001b[0m\n\u001b[1;32m     94\u001b[0m fit_patch_n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(fit_patch\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Fits the model to the linearized and normalized patch data\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_patch_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Outputs KMeans model fitted to the superpatch and will be used as input\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# to clustering_score and segment_TILs functions\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/546proj_mac/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/546proj_mac/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1525\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1521\u001b[0m best_inertia, best_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_init):\n\u001b[1;32m   1524\u001b[0m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n\u001b[0;32m-> 1525\u001b[0m     centers_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_centroids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m   1533\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/546proj_mac/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1021\u001b[0m, in \u001b[0;36m_BaseKMeans._init_centroids\u001b[0;34m(self, X, x_squared_norms, init, random_state, sample_weight, init_size, n_centroids)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight[init_indices]\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1021\u001b[0m     centers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_kmeans_plusplus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1029\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mchoice(\n\u001b[1;32m   1030\u001b[0m         n_samples,\n\u001b[1;32m   1031\u001b[0m         size\u001b[38;5;241m=\u001b[39mn_clusters,\n\u001b[1;32m   1032\u001b[0m         replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1033\u001b[0m         p\u001b[38;5;241m=\u001b[39msample_weight \u001b[38;5;241m/\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39msum(),\n\u001b[1;32m   1034\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/546proj_mac/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:238\u001b[0m, in \u001b[0;36m_kmeans_plusplus\u001b[0;34m(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    235\u001b[0m indices[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m center_id\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Initialize list of closest distances and calculate current potential\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m closest_dist_sq \u001b[38;5;241m=\u001b[39m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m current_pot \u001b[38;5;241m=\u001b[39m closest_dist_sq \u001b[38;5;241m@\u001b[39m sample_weight\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Pick the remaining n_clusters-1 points\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/546proj_mac/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:379\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    374\u001b[0m         YY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;129;01mor\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# To minimize precision issues with float32, we compute the distance\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# matrix on chunks of X and Y upcast to float64\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43m_euclidean_distances_upcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m    382\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m safe_sparse_dot(X, Y\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/546proj_mac/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:591\u001b[0m, in \u001b[0;36m_euclidean_distances_upcast\u001b[0;34m(X, XX, Y, YY, batch_size)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m     YY_chunk \u001b[38;5;241m=\u001b[39m YY[:, y_slice]\n\u001b[0;32m--> 591\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_chunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m d \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX_chunk\n\u001b[1;32m    593\u001b[0m d \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY_chunk\n",
      "File \u001b[0;32m~/miniconda3/envs/546proj_mac/lib/python3.11/site-packages/sklearn/utils/extmath.py:211\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 211\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m ):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/546proj_mac/lib/python3.11/site-packages/scipy/sparse/_base.py:1483\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[0;32m-> 1483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \n\u001b[1;32m   1486\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tilseg.refine_kmeans import kmean_to_spatial_model_superpatch_wrapper\n",
    "im_labels, dbscan_model, cluster_mask_dict = kmean_to_spatial_model_superpatch_wrapper(superpatch_path = repository_path + '/Example/Image Files/superpatch_training.tif',\n",
    "                                            in_dir_path = repository_path + 'Example/Image Files/TCGA-A2-A0CW-01Z-00-DX1',\n",
    "                                            spatial_hyperparameters= {'eps': 15,'min_samples': 100},\n",
    "                                            n_clusters = [1,2,4,5,6,7,8,9],\n",
    "                                            out_dir_path = repository_path + 'Example/Results',\n",
    "                                            save_TILs_overlay = True,\n",
    "                                            save_cluster_masks = True,\n",
    "                                            save_cluster_overlays =  True,\n",
    "                                            save_all_clusters_img = True,\n",
    "                                            save_csv = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLustering Results should have been saved to the `Results` Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/Image_1.png\" width=\"200\">  \n",
    "<span style=\"font-size: 6em;\">&rarr;</span>\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_2.png\" width=\"200\">\n",
    "<span style=\"font-size: 6em;\">&rarr;</span>\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"Notebook_Images/image_3.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BREAK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
